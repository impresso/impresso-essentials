# -*- coding: utf-8 -*-
"""s3_path_parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_-fTugHJfr7HsPFjnGTelvdC7E97NJ-K

#  s3 file path parser
"""

import re

# Define the possible values for various components
phases = "sandbox|staging|final"
processing_labels = (
    "embeddings|entities|langident|lingproc|ocrqa|newsagencies|topics|textreuse"
)
processing_subtype_labels = "embeddings|images|entities"
tasks = "ner|nel|tm|emb|lid|pos"
subtasks = "newsagency"
langs = "de|fr|en|lb|multilingual"


# Construct the regex pattern using re.VERBOSE
pattern = rf"""
^s3://
(?P<bucket>
    (?P<stage_number>\d{{2}})
    -processed-data-
    (?P<phase>{phases})
)
/ (?P<processing_label>{processing_labels})
(?: / (?P<processing_subtype_label>{processing_subtype_labels}) )?
/
(?P<run_id>
    (?P=processing_label)
    -
    (?P<model_id>
        (?P<task>{tasks})
        (?:_(?P<subtask>{subtasks}))?
        -
        (?P<model_specificity>[A-Za-z][A-Za-z_-]*)
        (?:_(?P<model_version>v(?P<model_major>\d+)\.(?P<model_minor>\d+)\.(?P<model_patch>\d+)))?
        -
        (?P<lang>{langs})
    )
    _
    (?P<run_version>v(?P<run_major>\d+)-(?P<run_minor>\d+)-(?P<run_patch>\d+))
)
(?:/(?P<provider_alias>[A-Za-z]+))?
(?:/(?P<media_alias>[A-Za-z0-9]+))
/
(?P<file_stem>
    (?: (?P=media_alias) - ) # Backreference here
    (?P<year>\d{{4}})
    (?: - (?P=processing_label) )?   # Backreference here
)
\.jsonl\.bz2$
"""

# Compile the regex pattern
regex = re.compile(pattern, re.VERBOSE)


def parse_s3_path(path):
    """
    Parses the given S3 path according to the defined pattern.

    Args:
        path (str): The S3 path to parse.

    Returns:
        dict: A dictionary of the matched components, or None if no match is found.
    """
    match = regex.match(path)
    if match:
        return match.groupdict()
    else:
        return None


def test_matching_paths(test_paths, verbose=True):
    """
    Tests paths that are expected to match the regex pattern.
    """

    print("Testing paths expected to match:")
    for path in test_paths:
        result = parse_s3_path(path)
        if result:
            print(f"✅ Passed: {path}")
            # Uncomment below to print the matched groups
            if verbose:
                for key, value in result.items():
                    print(f"  {key}: {value}")
        else:
            print(f"❌ Failed: {path} (Expected to match but did not)")
    print("-" * 80)


def test_non_matching_paths(test_paths, verbose=True):
    """
    Tests paths that are expected not to match the regex pattern.
    """

    print("Testing paths expected not to match:")
    for path in test_paths:
        result = parse_s3_path(path)
        if not result:
            print(f"✅ Passed: {path} (Correctly did not match)")
            if verbose:
                for key, value in result.items():
                    print(f"  {key}: {value}")
        else:
            print(f"❌ Failed: {path} (Expected not to match but did)")
    print("-" * 80)


correct_test_paths = [
    # Full path with all components
    "s3://01-processed-data-final/entities/embeddings/entities-ner-en_core_web_sm_v3.1.0-en_v1-0-0/Reuters/UK/UK-2021.jsonl.bz2",
    # Path without opt_processing_subtype_label
    "s3://02-processed-data-staging/langident/langident-lid-fasttext_v1.0.0-multilingual_v2-0-1/BBC/BBC-2020-langident.jsonl.bz2",
    # Path without provider_alias and model version
    "s3://03-processed-data-sandbox/topics/topics-tm-lda_model-en_v3-2-4/EXP/EXP-2021-topics.jsonl.bz2",
    # Path with optional subtask
    "s3://01-processed-data-final/newsagencies/newsagencies-ner_newsagency-model_v1.2.0-en_v1-0-0/AFP/AFP-2021-newsagencies.jsonl.bz2",
    # Path missing optional components
    "s3://42-processed-data-final/embeddings/embeddings-tm-mallet-de_v4-0-0/MEDIA/MEDIA-2022.jsonl.bz2",
    # Path with media_alias but no media_alias_file_stem
    "s3://42-processed-data-final/topics/topics-tm-bert_v3.0.0-en_v3-0-0/CNN/CNN-2024-topics.jsonl.bz2",
    # Path with
    "s3://41-processed-data-staging/lingproc/lingproc-pos-spacy_v3.6.0-multilingual_v1-0-2/IMP/IMP-2024.jsonl.bz2",
    # entity suggestion
    "s3://42-processed-data-final/embeddings/images/image-embeddings/embeddings-resnet_dino_clip-v0-0-1/bnl/actionfem/actionfem-1927-image-embeddings.jsonl.bz2",
]
# Run the test functions
# test_matching_paths(correct_test_paths,verbose=True)

incorrect_test_paths = [
    # Path with missing year in file_stem
    "s3://06-processed-data-final/ocrqa/ocrqa-ner-en_core_web_lg_v2.2.2-en_v2-1-0/NewYorkTimes/USA/USA-ocrqa.jsonl.bz2",
    # Path with missing processing_label_file_stem
    "s3://07-processed-data-final/lingproc/lingproc-lid-fasttext_v1.0.0-en_v1-0-0/2023.jsonl.bz2",
    # Path with invalid phase
    "s3://10-processed-data-production/entities/entities-ner-en_core_web_sm_v3.1.0-en_v1-0-0/2021-entities.jsonl.bz2",
    # Path with incorrect file extension
    "s3://11-processed-data-final/embeddings/embeddings-emb-word2vec_v4.0.0-multilingual_v4-0-0/2022-embeddings.txt",
    # Path missing processing_label in run_id
    "s3://12-processed-data-final/topics/topics-tm-lda_v1.0.0-en_v1-0-0/2021-topics.jsonl.bz2",
    # Path with incorrect model_id format
    "s3://13-processed-data-final/entities/entities-unknownmodel_v1.0.0-en_v1-0-0/2021-entities.jsonl.bz2",
    # Path with provider_alias but no media_alias
    "s3://09-processed-data-final/lingproc/lingproc-tm-lda_v1.0.0-en_v1-0-0/PROVIDER/MEDIA-2025-lingproc.jsonl.bz2",
]


# test_non_matching_paths(incorrect_test_paths,verbose=False)
